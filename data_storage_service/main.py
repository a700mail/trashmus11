import os
import logging
import json
import time
import sqlite3
import hashlib
from typing import Optional, Dict, Any, List
from pathlib import Path
import aiofiles
from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('storage_service.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_KEY = os.getenv("API_KEY", "default_key")
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./music_storage.db")
DATA_DIR = os.getenv("DATA_DIR", "data")
HOST = os.getenv("HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", "8002"))
SEARCH_CACHE_TTL = int(os.getenv("SEARCH_CACHE_TTL", "1800"))
TRACK_CACHE_TTL = int(os.getenv("TRACK_CACHE_TTL", "3600"))

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs(DATA_DIR, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="Data Storage Service",
    description="–°–µ—Ä–≤–∏—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç—Ä–µ–∫–∞—Ö –∏ –∫–µ—à–µ –ø–æ–∏—Å–∫–∞",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class TrackData(BaseModel):
    title: str
    url: str
    original_url: str
    duration: Optional[int]
    uploader: Optional[str]
    size_mb: float

class SearchCacheData(BaseModel):
    query: str
    results: List[Dict[str, Any]]

class UserTracksResponse(BaseModel):
    user_id: str
    tracks: List[Dict[str, Any]]
    total_count: int

# –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
class DatabaseManager:
    def __init__(self, db_path: str = "music_storage.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –¢–∞–±–ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∏—Ö —Ç—Ä–µ–∫–æ–≤
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS user_tracks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT NOT NULL,
                    title TEXT NOT NULL,
                    url TEXT NOT NULL,
                    original_url TEXT NOT NULL,
                    duration INTEGER,
                    uploader TEXT,
                    size_mb REAL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # –¢–∞–±–ª–∏—Ü–∞ –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS search_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query_hash TEXT UNIQUE NOT NULL,
                    query TEXT NOT NULL,
                    results TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    expires_at TIMESTAMP NOT NULL
                )
            ''')
            
            # –¢–∞–±–ª–∏—Ü–∞ cookies
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS cookies (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    domain TEXT NOT NULL,
                    cookie_data TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_user_tracks_user_id ON user_tracks(user_id)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_search_cache_query_hash ON search_cache(query_hash)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_search_cache_expires_at ON search_cache(expires_at)')
            
            conn.commit()
            conn.close()
            
            logging.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def get_connection(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        return sqlite3.connect(self.db_path)
    
    def save_user_track(self, user_id: str, track_data: TrackData) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO user_tracks (user_id, title, url, original_url, duration, uploader, size_mb)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                user_id,
                track_data.title,
                track_data.url,
                track_data.original_url,
                track_data.duration,
                track_data.uploader,
                track_data.size_mb
            ))
            
            conn.commit()
            conn.close()
            
            logging.info(f"‚úÖ –¢—Ä–µ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {track_data.title}")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–µ–∫–∞: {e}")
            return False
    
    def get_user_tracks(self, user_id: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT title, url, original_url, duration, uploader, size_mb, created_at
                FROM user_tracks
                WHERE user_id = ?
                ORDER BY created_at DESC
            ''', (user_id,))
            
            rows = cursor.fetchall()
            conn.close()
            
            tracks = []
            for row in rows:
                tracks.append({
                    'title': row[0],
                    'url': row[1],
                    'original_url': row[2],
                    'duration': row[3],
                    'uploader': row[4],
                    'size_mb': row[5],
                    'created_at': row[6]
                })
            
            return tracks
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–∫–æ–≤: {e}")
            return []
    
    def delete_user_track(self, user_id: str, track_url: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                DELETE FROM user_tracks
                WHERE user_id = ? AND url = ?
            ''', (user_id, track_url))
            
            deleted_count = cursor.rowcount
            conn.commit()
            conn.close()
            
            if deleted_count > 0:
                logging.info(f"‚úÖ –¢—Ä–µ–∫ —É–¥–∞–ª–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                return True
            else:
                logging.warning(f"‚ö†Ô∏è –¢—Ä–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {user_id} - {track_url}")
                return False
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç—Ä–µ–∫–∞: {e}")
            return False
    
    def save_search_cache(self, query: str, results: List[Dict[str, Any]]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # –°–æ–∑–¥–∞–µ–º —Ö–µ—à –∑–∞–ø—Ä–æ—Å–∞
            query_hash = hashlib.md5(query.lower().encode()).hexdigest()
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è
            expires_at = time.time() + SEARCH_CACHE_TTL
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
            cursor.execute('''
                INSERT OR REPLACE INTO search_cache (query_hash, query, results, expires_at)
                VALUES (?, ?, ?, ?)
            ''', (
                query_hash,
                query,
                json.dumps(results, ensure_ascii=False),
                expires_at
            ))
            
            conn.commit()
            conn.close()
            
            logging.info(f"‚úÖ –ö–µ—à –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return False
    
    def get_search_cache(self, query: str) -> Optional[List[Dict[str, Any]]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            query_hash = hashlib.md5(query.lower().encode()).hexdigest()
            current_time = time.time()
            
            cursor.execute('''
                SELECT results, expires_at
                FROM search_cache
                WHERE query_hash = ? AND expires_at > ?
            ''', (query_hash, current_time))
            
            row = cursor.fetchone()
            conn.close()
            
            if row:
                results = json.loads(row[0])
                logging.info(f"‚úÖ –ö–µ—à –ø–æ–∏—Å–∫–∞ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
                return results
            else:
                return None
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return None
    
    def cleanup_expired_cache(self) -> Dict[str, int]:
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–µ–∫—à–µ–≥–æ –∫–µ—à–∞"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            current_time = time.time()
            
            # –£–¥–∞–ª—è–µ–º –∏—Å—Ç–µ–∫—à–∏–π –∫–µ—à –ø–æ–∏—Å–∫–∞
            cursor.execute('''
                DELETE FROM search_cache
                WHERE expires_at <= ?
            ''', (current_time,))
            
            expired_searches = cursor.rowcount
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ç—Ä–µ–∫–∏ (—Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π)
            thirty_days_ago = current_time - (30 * 24 * 3600)
            cursor.execute('''
                DELETE FROM user_tracks
                WHERE created_at < ?
            ''', (thirty_days_ago,))
            
            expired_tracks = cursor.rowcount
            
            conn.commit()
            conn.close()
            
            if expired_searches > 0 or expired_tracks > 0:
                logging.info(f"üßπ –û—á–∏—â–µ–Ω –∏—Å—Ç–µ–∫—à–∏–π –∫–µ—à: {expired_searches} –ø–æ–∏—Å–∫–æ–≤, {expired_tracks} —Ç—Ä–µ–∫–æ–≤")
            
            return {
                "expired_searches": expired_searches,
                "expired_tracks": expired_tracks
            }
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞: {e}")
            return {"expired_searches": 0, "expired_tracks": 0}
    
    def get_database_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–∫–æ–≤
            cursor.execute('SELECT COUNT(*) FROM user_tracks')
            total_tracks = cursor.fetchone()[0]
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            cursor.execute('SELECT COUNT(DISTINCT user_id) FROM user_tracks')
            unique_users = cursor.fetchone()[0]
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤
            cursor.execute('SELECT COUNT(*) FROM search_cache')
            cached_searches = cursor.fetchone()[0]
            
            # –†–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            db_size = os.path.getsize(self.db_path) if os.path.exists(self.db_path) else 0
            
            conn.close()
            
            return {
                "total_tracks": total_tracks,
                "unique_users": unique_users,
                "cached_searches": cached_searches,
                "database_size_mb": db_size / (1024 * 1024)
            }
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

# –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏ cookies
class CookiesManager:
    def __init__(self, cookies_file: str = "cookies.txt"):
        self.cookies_file = cookies_file
        self.cookies_dir = DATA_DIR
    
    def get_cookies_path(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É cookies"""
        return os.path.join(self.cookies_dir, self.cookies_file)
    
    def save_cookies(self, cookies_data: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ cookies"""
        try:
            cookies_path = self.get_cookies_path()
            
            async def save_async():
                async with aiofiles.open(cookies_path, 'w', encoding='utf-8') as f:
                    await f.write(cookies_data)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            import asyncio
            asyncio.run(save_async())
            
            logging.info(f"‚úÖ Cookies —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {cookies_path}")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è cookies: {e}")
            return False
    
    def get_cookies(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ cookies"""
        try:
            cookies_path = self.get_cookies_path()
            
            if not os.path.exists(cookies_path):
                return None
            
            async def read_async():
                async with aiofiles.open(cookies_path, 'r', encoding='utf-8') as f:
                    return await f.read()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ
            import asyncio
            cookies_data = asyncio.run(read_async())
            
            return cookies_data
            
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è cookies: {e}")
            return None
    
    def delete_cookies(self) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ cookies"""
        try:
            cookies_path = self.get_cookies_path()
            
            if os.path.exists(cookies_path):
                os.remove(cookies_path)
                logging.info(f"‚úÖ Cookies —É–¥–∞–ª–µ–Ω—ã: {cookies_path}")
                return True
            else:
                logging.warning(f"‚ö†Ô∏è –§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω: {cookies_path}")
                return False
                
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è cookies: {e}")
            return False

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
db_manager = DatabaseManager()
cookies_manager = CookiesManager()

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ API –∫–ª—é—á–∞
async def verify_api_key(authorization: str = Header(None)):
    if not authorization:
        raise HTTPException(status_code=401, detail="API –∫–ª—é—á –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
    
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
    
    api_key = authorization.replace("Bearer ", "")
    if api_key != API_KEY:
        raise HTTPException(status_code=401, detail="–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á")
    
    return api_key

# API endpoints
@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        conn = db_manager.get_connection()
        conn.close()
        
        return {
            "status": "healthy",
            "service": "Data Storage Service",
            "timestamp": time.time(),
            "database_connected": True
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "service": "Data Storage Service",
            "timestamp": time.time(),
            "database_connected": False,
            "error": str(e)
        }

@app.post("/tracks/{user_id}")
async def save_track(
    user_id: str,
    track_data: TrackData,
    api_key: str = Depends(verify_api_key)
):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        if await db_manager.save_user_track(user_id, track_data):
            return {"message": "–¢—Ä–µ–∫ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω", "user_id": user_id}
        else:
            raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–µ–∫–∞")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–µ–∫–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–µ–∫–∞")

@app.get("/tracks/{user_id}", response_model=UserTracksResponse)
async def get_user_tracks(
    user_id: str,
    api_key: str = Depends(verify_api_key)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        tracks = db_manager.get_user_tracks(user_id)
        return UserTracksResponse(
            user_id=user_id,
            tracks=tracks,
            total_count=len(tracks)
        )
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–∫–æ–≤: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–∫–æ–≤")

@app.delete("/tracks/{user_id}")
async def delete_user_track(
    user_id: str,
    track_url: str,
    api_key: str = Depends(verify_api_key)
):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        if db_manager.delete_user_track(user_id, track_url):
            return {"message": "–¢—Ä–µ–∫ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω", "user_id": user_id}
        else:
            raise HTTPException(status_code=404, detail="–¢—Ä–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç—Ä–µ–∫–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç—Ä–µ–∫–∞")

@app.post("/cache/search")
async def save_search_cache(
    cache_data: SearchCacheData,
    api_key: str = Depends(verify_api_key)
):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞"""
    try:
        if db_manager.save_search_cache(cache_data.query, cache_data.results):
            return {"message": "–ö–µ—à –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω", "query": cache_data.query}
        else:
            raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞")

@app.get("/cache/search")
async def get_search_cache(
    query: str,
    api_key: str = Depends(verify_api_key)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–µ—à–∞ –ø–æ–∏—Å–∫–∞"""
    try:
        results = db_manager.get_search_cache(query)
        if results:
            return {"query": query, "results": results, "cached": True}
        else:
            return {"query": query, "results": [], "cached": False}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–µ—à–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–µ—à–∞")

@app.post("/cookies")
async def save_cookies(
    cookies_data: str,
    api_key: str = Depends(verify_api_key)
):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ cookies"""
    try:
        if cookies_manager.save_cookies(cookies_data):
            return {"message": "Cookies —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"}
        else:
            raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è cookies")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è cookies: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è cookies")

@app.get("/cookies")
async def get_cookies(api_key: str = Depends(verify_api_key)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ cookies"""
    try:
        cookies = cookies_manager.get_cookies()
        if cookies:
            return {"cookies": cookies, "exists": True}
        else:
            return {"cookies": "", "exists": False}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è cookies: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è cookies")

@app.delete("/cookies")
async def delete_cookies(api_key: str = Depends(verify_api_key)):
    """–£–¥–∞–ª–µ–Ω–∏–µ cookies"""
    try:
        if cookies_manager.delete_cookies():
            return {"message": "Cookies —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω—ã"}
        else:
            raise HTTPException(status_code=404, detail="–§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è cookies: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è cookies")

@app.post("/cache/cleanup")
async def cleanup_cache(api_key: str = Depends(verify_api_key)):
    """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–µ–∫—à–µ–≥–æ –∫–µ—à–∞"""
    try:
        cleanup_stats = db_manager.cleanup_expired_cache()
        return {
            "message": "–ö–µ—à –æ—á–∏—â–µ–Ω",
            "stats": cleanup_stats
        }
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞")

@app.get("/stats")
async def get_stats(api_key: str = Depends(verify_api_key)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        db_stats = db_manager.get_database_stats()
        return {
            "service": "Data Storage Service",
            "timestamp": time.time(),
            "database_stats": db_stats
        }
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

# –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞
@app.on_event("startup")
async def startup_event():
    """–°–æ–±—ã—Ç–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–∞"""
    logging.info("üöÄ Data Storage Service –∑–∞–ø—É—â–µ–Ω")
    
    # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞
    import asyncio
    
    async def periodic_cleanup():
        while True:
            try:
                await asyncio.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
                cleanup_stats = db_manager.cleanup_expired_cache()
                if cleanup_stats["expired_searches"] > 0 or cleanup_stats["expired_tracks"] > 0:
                    logging.info(f"üßπ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞: {cleanup_stats}")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏: {e}")
                await asyncio.sleep(300)  # –ñ–¥–µ–º 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    asyncio.create_task(periodic_cleanup())

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=HOST,
        port=PORT,
        reload=True,
        workers=1  # –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    )
