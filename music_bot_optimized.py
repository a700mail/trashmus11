import logging
import os
import asyncio
import json
import time
import random
import secrets
import yt_dlp
import browser_cookie3
from http.cookiejar import MozillaCookieJar
from aiogram import Bot, Dispatcher, types
from aiogram import F
from aiogram.filters import Command
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, KeyboardButton
from aiogram.fsm.state import StatesGroup, State
from aiogram.fsm.context import FSMContext

import re
from functools import partial, lru_cache
import aiohttp
from datetime import datetime, timedelta
from collections import deque
from asyncio import PriorityQueue
from concurrent.futures import ThreadPoolExecutor
import threading
from typing import Dict, List, Optional, Tuple
import weakref

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    from dotenv import load_dotenv
    load_dotenv()
    logging.info("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ .env —Ñ–∞–π–ª–∞")
except ImportError:
    logging.warning("‚ö†Ô∏è python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ —Å–∏—Å—Ç–µ–º—ã.")
except Exception as e:
    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ .env —Ñ–∞–π–ª–∞: {e}")

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ===
API_TOKEN = os.getenv("BOT_TOKEN")
if not API_TOKEN:
    raise RuntimeError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

MAX_FILE_SIZE_MB = 50
CACHE_DIR = "cache"
COOKIES_FILE = os.path.join(os.path.dirname(__file__), "cookies.txt")
TRACKS_FILE = os.path.join(os.path.dirname(__file__), "tracks.json")
SEARCH_CACHE_FILE = os.path.join(os.path.dirname(__file__), "search_cache.json")

# === –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò ===
MAX_CONCURRENT_DOWNLOADS = 8  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
MAX_CONCURRENT_DOWNLOADS_PER_USER = 3  # –ë–æ–ª—å—à–µ –∑–∞–≥—Ä—É–∑–æ–∫ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
MAX_CACHE_SIZE_MB = 1024  # 1GB –∫—ç—à
CACHE_CLEANUP_THRESHOLD = 0.8  # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ 80% –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–∏
DOWNLOAD_TIMEOUT = 60  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
SEARCH_CACHE_TTL = 1800  # 30 –º–∏–Ω—É—Ç –∫—ç—à –ø–æ–∏—Å–∫–∞
PAGE_SIZE = 15  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã

# === –ì–õ–û–ë–ê–õ–¨–ù–´–ï –û–ë–™–ï–ö–¢–´ ===
user_tracks = {}
user_recommendation_history = {}
track_metadata_cache = {}
search_cache = {}

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –û–ß–ï–†–ï–î–ò ===
PREMIUM_QUEUE = PriorityQueue()
REGULAR_QUEUE = deque(maxlen=1000)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏

# === –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–ì–†–£–ó–û–ö ===
yt_executor = ThreadPoolExecutor(
    max_workers=12,  # –£–≤–µ–ª–∏—á–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
    thread_name_prefix="yt_downloader",
    thread_name_prefix="yt_downloader"
)
download_semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)
user_download_semaphores = {}
ACTIVE_DOWNLOADS = 0

# === –ö–≠–®–ò–†–û–í–ê–ù–ò–ï ===
@lru_cache(maxsize=1000)
def get_cached_metadata(url: str) -> Optional[dict]:
    """–ö—ç—à–∏—Ä—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–æ–≤ –≤ –ø–∞–º—è—Ç–∏"""
    return track_metadata_cache.get(url)

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot_optimized.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=API_TOKEN)
dp = Dispatcher()
os.makedirs(CACHE_DIR, exist_ok=True)

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

class DownloadManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–≥—Ä—É–∑–æ–∫ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self):
        self.active_downloads = 0
        self.download_history = deque(maxlen=100)
        self.failed_downloads = {}
        self.retry_delays = {}
    
    async def download_with_retry(self, url: str, user_id: str, max_retries: int = 3) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ç–æ—Ä–∞–º–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        if url in self.failed_downloads:
            last_fail_time = self.failed_downloads[url].get('time', 0)
            if time.time() - last_fail_time < 300:  # 5 –º–∏–Ω—É—Ç –∫—ç—à –æ—à–∏–±–æ–∫
                return None
        
        for attempt in range(max_retries):
            try:
                result = await self._download_single(url, user_id)
                if result:
                    self.download_history.append({
                        'url': url,
                        'user_id': user_id,
                        'success': True,
                        'timestamp': time.time()
                    })
                    return result
            except Exception as e:
                logging.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {url}: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        
        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—É—é –ø–æ–ø—ã—Ç–∫—É
        self.failed_downloads[url] = {
            'time': time.time(),
            'user_id': user_id,
            'attempts': max_retries
        }
        return None
    
    async def _download_single(self, url: str, user_id: str) -> Optional[str]:
        """–û–¥–∏–Ω–æ—á–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
        async with download_semaphore:
            self.active_downloads += 1
            try:
                loop = asyncio.get_running_loop()
                result = await loop.run_in_executor(
                    yt_executor, 
                    self._download_blocking, 
                    url, 
                    user_id
                )
                return result
            finally:
                self.active_downloads -= 1
    
    def _download_blocking(self, url: str, user_id: str) -> Optional[str]:
        """–ë–ª–æ–∫–∏—Ä—É—é—â–µ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        try:
            ydl_opts = {
                'format': 'bestaudio/best',
                'quiet': True,
                'no_warnings': True,
                'ignoreerrors': True,
                'timeout': DOWNLOAD_TIMEOUT,
                'retries': 2,
                'nocheckcertificate': True,
                'extractaudio': True,
                'audioformat': 'mp3',
                'audioquality': '192K',
                'outtmpl': os.path.join(CACHE_DIR, f'{user_id}_%(title)s_%(epoch)s.%(ext)s'),
            }
            
            if os.path.exists(COOKIES_FILE):
                ydl_opts['cookiefile'] = COOKIES_FILE
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                if info and 'requested_downloads' in info:
                    downloaded_file = info['requested_downloads'][0]['filepath']
                    return downloaded_file
            
            return None
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {url}: {e}")
            return None

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–≥—Ä—É–∑–æ–∫
download_manager = DownloadManager()

class CacheManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–æ–π"""
    
    def __init__(self, max_size_mb: int = MAX_CACHE_SIZE_MB):
        self.max_size_mb = max_size_mb
        self.cache_info = {}
        self.last_cleanup = time.time()
    
    def add_file(self, file_path: str, metadata: dict):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –≤ –∫—ç—à"""
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024 * 1024)
            self.cache_info[file_path] = {
                'size_mb': size_mb,
                'metadata': metadata,
                'added_time': time.time(),
                'access_time': time.time()
            }
            self._check_cleanup()
    
    def get_file(self, file_path: str) -> Optional[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –∏–∑ –∫—ç—à–∞"""
        if file_path in self.cache_info:
            self.cache_info[file_path]['access_time'] = time.time()
            return self.cache_info[file_path]['metadata']
        return None
    
    def _check_cleanup(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞"""
        current_time = time.time()
        if current_time - self.last_cleanup < 300:  # –ö–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
            return
        
        total_size = sum(info['size_mb'] for info in self.cache_info.values())
        if total_size > self.max_size_mb * CACHE_CLEANUP_THRESHOLD:
            self._cleanup_cache()
            self.last_cleanup = current_time
    
    def _cleanup_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à, —É–¥–∞–ª—è—è —Å—Ç–∞—Ä—ã–µ –∏ —Ä–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ–∞–π–ª—ã"""
        try:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            sorted_files = sorted(
                self.cache_info.items(),
                key=lambda x: x[1]['access_time']
            )
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            target_size = self.max_size_mb * 0.5  # –¶–µ–ª—å - 50% –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞
            current_size = sum(info['size_mb'] for info in self.cache_info.values())
            
            for file_path, info in sorted_files:
                if current_size <= target_size:
                    break
                
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        logging.info(f"–£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª –∫—ç—à–∞: {file_path}")
                    del self.cache_info[file_path]
                    current_size -= info['size_mb']
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∫—ç—à–∞ {file_path}: {e}")
            
            logging.info(f"–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –¢–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä: {current_size:.2f}MB")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞
cache_manager = CacheManager()

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –°–ö–ê–ß–ò–í–ê–ù–ò–Ø ===

async def download_track_optimized(user_id: str, url: str, is_premium: bool = False) -> Optional[str]:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ç—Ä–µ–∫–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_file = await _check_cache_for_url(url)
        if cached_file:
            logging.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {cached_file}")
            return cached_file
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        result = await download_manager.download_with_retry(url, user_id)
        
        if result:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à
            metadata = {
                'url': url,
                'user_id': user_id,
                'downloaded_time': time.time(),
                'is_premium': is_premium
            }
            cache_manager.add_file(result, metadata)
            
            logging.info(f"–¢—Ä–µ–∫ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω: {result}")
            return result
        
        return None
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
        return None

async def _check_cache_for_url(url: str) -> Optional[str]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫—ç—à –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ –ø–æ URL"""
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é –ª–æ–≥–∏–∫—É –ø–æ–∏—Å–∫–∞ –≤ –∫—ç—à–µ
    # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
    return None

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–ê ===

@lru_cache(maxsize=500)
async def search_tracks_cached(query: str, limit: int = 10) -> List[dict]:
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ç—Ä–µ–∫–æ–≤"""
    cache_key = f"{query}_{limit}"
    
    if cache_key in search_cache:
        cache_entry = search_cache[cache_key]
        if time.time() - cache_entry['timestamp'] < SEARCH_CACHE_TTL:
            return cache_entry['results']
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    results = await _perform_search(query, limit)
    
    # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    search_cache[cache_key] = {
        'results': results,
        'timestamp': time.time()
    }
    
    return results

async def _perform_search(query: str, limit: int) -> List[dict]:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Ç—Ä–µ–∫–æ–≤"""
    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø–æ–∏—Å–∫–∞
    # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
    return []

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò ===

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã start"""
    try:
        await message.answer(
            "üéµ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Music Bot!\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /search –¥–ª—è –ø–æ–∏—Å–∫–∞ –º—É–∑—ã–∫–∏ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Ç—Ä–µ–∫."
        )
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ –∫–æ–º–∞–Ω–¥–µ start: {e}")

@dp.message(Command("search"))
async def cmd_search(message: types.Message):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ç—Ä–µ–∫–æ–≤"""
    try:
        query = message.text.replace("/search", "").strip()
        if not query:
            await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —á—Ç–æ –∏—Å–∫–∞—Ç—å. –ù–∞–ø—Ä–∏–º–µ—Ä: /search –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Å–Ω–∏")
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
        loading_msg = await message.answer("üîç –ò—â–µ–º —Ç—Ä–µ–∫–∏...")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        results = await search_tracks_cached(query, PAGE_SIZE)
        
        if results:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = "üéµ –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏:\n\n"
            for i, track in enumerate(results[:PAGE_SIZE], 1):
                response += f"{i}. {track.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} - {track.get('artist', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
            
            await loading_msg.edit_text(response)
        else:
            await loading_msg.edit_text("‚ùå –¢—Ä–µ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ –ø–æ–∏—Å–∫–µ: {e}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

@dp.message()
async def handle_url(message: types.Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
        urls = re.findall(r'https?://[^\s]+', message.text)
        if not urls:
            return
        
        url = urls[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Å–µ—Ä–≤–∏—Å
        if not _is_supported_url(url):
            await message.answer("‚ùå –≠—Ç–æ—Ç —Å–µ—Ä–≤–∏—Å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
        loading_msg = await message.answer("üì• –°–∫–∞—á–∏–≤–∞–µ–º —Ç—Ä–µ–∫...")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ç—Ä–µ–∫
        file_path = await download_track_optimized(str(message.from_user.id), url)
        
        if file_path and os.path.exists(file_path):
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
            try:
                with open(file_path, 'rb') as audio_file:
                    await message.answer_audio(
                        audio_file,
                        title=os.path.basename(file_path),
                        performer="Music Bot"
                    )
                
                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
                await _cleanup_file(file_path)
                
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞: {e}")
                await loading_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞.")
        else:
            await loading_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ç—Ä–µ–∫.")
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL: {e}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏.")

def _is_supported_url(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ URL"""
    supported_domains = [
        'youtube.com', 'youtu.be', 'soundcloud.com', 'spotify.com',
        'vk.com', 'vk.ru', 'deezer.com', 'tidal.com'
    ]
    return any(domain in url.lower() for domain in supported_domains)

async def _cleanup_file(file_path: str):
    """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
            logging.info(f"–§–∞–π–ª —É–¥–∞–ª–µ–Ω: {file_path}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")

# === –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ===

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
    try:
        logging.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Music Bot...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
        asyncio.create_task(_background_cleanup())
        asyncio.create_task(_cache_monitor())
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
        await dp.start_polling(bot)
        
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ main: {e}")
    finally:
        # –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
        yt_executor.shutdown(wait=True)
        logging.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

async def _background_cleanup():
    """–§–æ–Ω–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
    while True:
        try:
            await asyncio.sleep(300)  # –ö–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –≤ –∫—ç—à–µ
            current_time = time.time()
            expired_keys = [
                key for key, entry in search_cache.items()
                if current_time - entry['timestamp'] > SEARCH_CACHE_TTL
            ]
            
            for key in expired_keys:
                del search_cache[key]
            
            if expired_keys:
                logging.info(f"–û—á–∏—â–µ–Ω–æ {len(expired_keys)} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –∫—ç—à–∞")
                
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–µ: {e}")

async def _cache_monitor():
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫—ç—à–∞"""
    while True:
        try:
            await asyncio.sleep(600)  # –ö–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            cache_size = sum(info['size_mb'] for info in cache_manager.cache_info.values())
            logging.info(f"–†–∞–∑–º–µ—Ä –∫—ç—à–∞: {cache_size:.2f}MB / {MAX_CACHE_SIZE_MB}MB")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ –∫—ç—à–∞: {e}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logging.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
